{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitsoampipenvd935c3e85a8642968f9f9240671058a4",
   "display_name": "Python 3.8.2 64-bit ('soam': pipenv)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# SOAM Quickstart\n",
    "How to make an end to end project using SOAM modules and tools.\n",
    "\n",
    "![soam_pipeline](documentation/images/SoaM_diagram.png)\n",
    "\n",
    "\n",
    "This library pipeline supports any data source.\n",
    "The process is structured in different stages:\n",
    "* Extraction: manages the connection with the database, the time granularity and the aggregation level of the input data.\n",
    "* Preprocessing: lets select among out of the box tools to perform standard tasks as normalization or fill nan values.\n",
    "* Forecasting: fits a model and predict results.\n",
    "* Postprocessing: modifies the results based on business/real information or create analysis with the predicted values,\n",
    " such as an anomaly detection.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "This stage extracts data from the needed sources to build the condensed dataset for the next steps. This tends to be project dependent."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Establish the connection with the database"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soam.workflow.time_series_extractor import TimeSeriesExtractor\n",
    "from muttlib.dbconn import get_client"
   ]
  },
  {
   "source": [
    "Postgres config set up"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_cfg = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432,\n",
    "    \"db_type\": \"postgres\",\n",
    "    \"username\": \"mutt\",\n",
    "    \"password\": \"mutt\",\n",
    "    \"database\": \"sqlalchemy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_client = get_client(pg_cfg)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<muttlib.dbconn.postgres.PgClient at 0x7f1969940040>"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "pg_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = TimeSeriesExtractor(db=pg_client, table_name='stocks_valuation')"
   ]
  },
  {
   "source": [
    "#### Then it converts the full dataset to the desired time granularity and aggregation level by some categorical attribute/s and return it as a pandas data frame.\n",
    "In this case we define the following: <br>\n",
    "- Time granularity: <br>\n",
    "     - Start date: 2021-03-01 <br>\n",
    "     - End date: 2021-03-20\n",
    "- Aggregation Level:\n",
    "    - Just stay with Apple's (AAPL) stock information."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_query_kwargs={\n",
    "    'columns': '*',\n",
    "    'timestamp_col': 'date',\n",
    "    'start_date': \"2021-03-01\",\n",
    "    'end_date': \"2021-03-20\",\n",
    "    'extra_where_conditions': [\"symbol = 'AAPL'\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index        date symbol  avg_num_trades  avg_price\n",
       "0      0  2021-03-18   AAPL    84353.996528  121.75000\n",
       "1      1  2021-03-17   AAPL    77730.997222  124.09795\n",
       "2      2  2021-03-16   AAPL    80019.400000  125.96750\n",
       "3      3  2021-03-15   AAPL    64298.996528  122.21000\n",
       "4      4  2021-03-12   AAPL    61184.062500  120.16500"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>date</th>\n      <th>symbol</th>\n      <th>avg_num_trades</th>\n      <th>avg_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2021-03-18</td>\n      <td>AAPL</td>\n      <td>84353.996528</td>\n      <td>121.75000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2021-03-17</td>\n      <td>AAPL</td>\n      <td>77730.997222</td>\n      <td>124.09795</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2021-03-16</td>\n      <td>AAPL</td>\n      <td>80019.400000</td>\n      <td>125.96750</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2021-03-15</td>\n      <td>AAPL</td>\n      <td>64298.996528</td>\n      <td>122.21000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2021-03-12</td>\n      <td>AAPL</td>\n      <td>61184.062500</td>\n      <td>120.16500</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 318
    }
   ],
   "source": [
    "extractor.run(build_query_kwargs=build_query_kwargs).head()"
   ]
  },
  {
   "source": [
    "Store the query into a <b>pandas dataframe</b> to facilitate data manipulation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index        date symbol  avg_num_trades  avg_price\n",
       "0      0  2021-03-18   AAPL    84353.996528  121.75000\n",
       "1      1  2021-03-17   AAPL    77730.997222  124.09795\n",
       "2      2  2021-03-16   AAPL    80019.400000  125.96750\n",
       "3      3  2021-03-15   AAPL    64298.996528  122.21000\n",
       "4      4  2021-03-12   AAPL    61184.062500  120.16500"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>date</th>\n      <th>symbol</th>\n      <th>avg_num_trades</th>\n      <th>avg_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2021-03-18</td>\n      <td>AAPL</td>\n      <td>84353.996528</td>\n      <td>121.75000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2021-03-17</td>\n      <td>AAPL</td>\n      <td>77730.997222</td>\n      <td>124.09795</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2021-03-16</td>\n      <td>AAPL</td>\n      <td>80019.400000</td>\n      <td>125.96750</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2021-03-15</td>\n      <td>AAPL</td>\n      <td>64298.996528</td>\n      <td>122.21000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2021-03-12</td>\n      <td>AAPL</td>\n      <td>61184.062500</td>\n      <td>120.16500</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 330
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = extractor.run(build_query_kwargs = build_query_kwargs)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soam.workflow import Transformer"
   ]
  },
  {
   "source": [
    "Import the MinMaxScaler from Scikit-Learn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "source": [
    "Create the Transformer object and pass the scaler as the transformer parameter."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Transformer(transformer = scaler)"
   ]
  },
  {
   "source": [
    "We want to normalize the average price values.\n",
    "\n",
    "We convert the column to an array and swap the axes to pass it to the scaler."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([df.avg_price])\n",
    "data = np.swapaxes(data, 0, 1)"
   ]
  },
  {
   "source": [
    "Run the soam transform object."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[0.38075061],\n",
       "        [0.66500605],\n",
       "        [0.89134383],\n",
       "        [0.43644068],\n",
       "        [0.18886199],\n",
       "        [0.43946731],\n",
       "        [0.26694915],\n",
       "        [0.22033898],\n",
       "        [0.        ],\n",
       "        [0.13892252],\n",
       "        [0.30326877],\n",
       "        [0.62590799],\n",
       "        [1.        ],\n",
       "        [0.81779661]]),\n",
       " MinMaxScaler())"
      ]
     },
     "metadata": {},
     "execution_count": 335
    }
   ],
   "source": [
    "ts.run(data)"
   ]
  },
  {
   "source": [
    "Change the values of avg_price for the scaled ones."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index        date symbol  avg_num_trades  avg_price\n",
       "0      0  2021-03-18   AAPL    84353.996528   0.380751\n",
       "1      1  2021-03-17   AAPL    77730.997222   0.665006\n",
       "2      2  2021-03-16   AAPL    80019.400000   0.891344\n",
       "3      3  2021-03-15   AAPL    64298.996528   0.436441\n",
       "4      4  2021-03-12   AAPL    61184.062500   0.188862"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>date</th>\n      <th>symbol</th>\n      <th>avg_num_trades</th>\n      <th>avg_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2021-03-18</td>\n      <td>AAPL</td>\n      <td>84353.996528</td>\n      <td>0.380751</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2021-03-17</td>\n      <td>AAPL</td>\n      <td>77730.997222</td>\n      <td>0.665006</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2021-03-16</td>\n      <td>AAPL</td>\n      <td>80019.400000</td>\n      <td>0.891344</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2021-03-15</td>\n      <td>AAPL</td>\n      <td>64298.996528</td>\n      <td>0.436441</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2021-03-12</td>\n      <td>AAPL</td>\n      <td>61184.062500</td>\n      <td>0.188862</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 336
    }
   ],
   "source": [
    "df.avg_price = ts.run(data)[0]\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "We drop the unnecesary columns and adapt the column names for the Fb Prophet for the Forecasting."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           ds         y\n",
       "0  2021-03-18  0.380751\n",
       "1  2021-03-17  0.665006\n",
       "2  2021-03-16  0.891344\n",
       "3  2021-03-15  0.436441\n",
       "4  2021-03-12  0.188862"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ds</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-03-18</td>\n      <td>0.380751</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-03-17</td>\n      <td>0.665006</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-03-16</td>\n      <td>0.891344</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-03-15</td>\n      <td>0.436441</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-03-12</td>\n      <td>0.188862</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 337
    }
   ],
   "source": [
    "df = df[['date', 'avg_price']]\n",
    "df.rename(columns = {\n",
    "    'date': 'ds',\n",
    "    'avg_price': 'y'}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "# SoaMFlow\n",
    "\n",
    "Putting all together with SoaMFlow.\n",
    "\n",
    "### WORK IN PROGRESS..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soam.core import SoamFlow\n",
    "from prefect import task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def load_df(df):\n",
    "    df.to_csv(\"hola.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SoamFlow(name=\"test\") as test:\n",
    "    df = extractor(build_query_kwargs)\n",
    "    df = ts(data)\n",
    "    load_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2021-03-25 18:50:23-0300] INFO - prefect.FlowRunner | Beginning Flow run for 'test'\n",
      "[2021-03-25 18:50:23-0300] INFO - prefect.TaskRunner | Task 'TimeSeriesExtractor': Starting task run...\n",
      "[2021-03-25 18:50:23-0300] INFO - prefect.TaskRunner | Task 'TimeSeriesExtractor': Finished task run for task with final state: 'Success'\n",
      "[2021-03-25 18:50:23-0300] INFO - prefect.TaskRunner | Task 'Transformer': Starting task run...\n",
      "[2021-03-25 18:50:23-0300] INFO - prefect.TaskRunner | Task 'Transformer': Finished task run for task with final state: 'Success'\n",
      "[2021-03-25 18:50:23-0300] INFO - prefect.TaskRunner | Task 'load_df': Starting task run...\n",
      "[2021-03-25 18:50:23-0300] ERROR - prefect.TaskRunner | Unexpected error: AttributeError(\"'tuple' object has no attribute 'to_csv'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/scafati98/MUTT/soam/quickstart_env/lib/python3.8/site-packages/prefect/engine/runner.py\", line 48, in inner\n",
      "    new_state = method(self, state, *args, **kwargs)\n",
      "  File \"/home/scafati98/MUTT/soam/quickstart_env/lib/python3.8/site-packages/prefect/engine/task_runner.py\", line 865, in get_task_run_state\n",
      "    value = prefect.utilities.executors.run_task_with_timeout(\n",
      "  File \"/home/scafati98/MUTT/soam/quickstart_env/lib/python3.8/site-packages/prefect/utilities/executors.py\", line 299, in run_task_with_timeout\n",
      "    return task.run(*args, **kwargs)  # type: ignore\n",
      "  File \"<ipython-input-283-580bcac43fd2>\", line 3, in load_df\n",
      "    df.to_csv(\"hola.csv\")\n",
      "AttributeError: 'tuple' object has no attribute 'to_csv'\n",
      "[2021-03-25 18:50:23-0300] INFO - prefect.TaskRunner | Task 'load_df': Finished task run for task with final state: 'Failed'\n",
      "[2021-03-25 18:50:23-0300] INFO - prefect.FlowRunner | Flow run FAILED: some reference tasks failed.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Failed: \"Some reference tasks failed.\">"
      ]
     },
     "metadata": {},
     "execution_count": 294
    }
   ],
   "source": [
    "test.run()"
   ]
  }
 ]
}